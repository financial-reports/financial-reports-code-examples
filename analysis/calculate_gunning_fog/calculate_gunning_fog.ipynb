{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Calculating Readability with the Gunning Fog Index\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Financial reports can be dense and filled with jargon. The **Gunning Fog Index** is a classic readability metric that estimates the years of formal education a person needs to understand a piece of text on the first reading. \n",
    "\n",
    "A lower score indicates easier-to-read text. For financial documents, this can be a valuable proxy for transparency and clarity.\n",
    "\n",
    "**Formula:** `0.4 * ( (words / sentences) + 100 * (complex_words / words) )`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, we import our reusable calculation logic from `utils.py` and the `nltk` library for natural language processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from utils import calculate_gunning_fog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the `punkt` tokenizer from `nltk` to correctly split text into sentences and words. If you haven't downloaded it before, the next cell will do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the 'punkt' tokenizer models (only needs to be done once)\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Sample Data\n",
    "\n",
    "We'll use the `sample_text.txt` file included in this directory. It contains a paragraph from a fictional financial report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample_text.txt', 'r', encoding='utf-8') as f:\n",
    "    sample_text = f.read()\n",
    "\n",
    "print(\"--- Sample Text ---\")\n",
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate the Score\n",
    "\n",
    "Now, we pass the text to our function from `utils.py` to get the Gunning Fog score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fog_score = calculate_gunning_fog(sample_text)\n",
    "\n",
    "print(f\"Gunning Fog Index: {fog_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interpretation\n",
    "\n",
    "How to interpret the score:\n",
    "\n",
    "| Score | Reading Level |\n",
    "| :--- | :--- |\n",
    "| 17 | College graduate |\n",
    "| 16 | College senior |\n",
    "| 15 | College junior |\n",
    "| 14 | College sophomore |\n",
    "| 13 | College freshman |\n",
    "| 12 | High school senior |\n",
    "| 10-11 | High school junior/sophomore |\n",
    "| 8-9 | Junior high |\n",
    "| 6 | Sixth grade |\n",
    "\n",
    "A score above 12 is generally considered difficult for a general audience. Financial and legal documents often score in the 15-20 range."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
