{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Case: End-to-End Generative Sentiment Analysis\n",
    "\n",
    "This notebook demonstrates a complete workflow for performing advanced, AI-driven sentiment analysis on a financial filing.\n",
    "\n",
    "**Our Goal:** Answer a specific, nuanced question about a document (e.g., \"*What is the sentiment regarding future business outlook?*\") and receive a structured, auditable JSON response.\n",
    "\n",
    "**The Workflow:**\n",
    "1.  **Setup:** Load API keys and initialize clients for FinancialReports and Google Gemini.\n",
    "2.  **Step 1: Find Filing:** Query the FinancialReports API to find a specific filing (e.g., the latest Annual Report for a company).\n",
    "3.  **Step 2: Fetch Markdown:** Use the `filing_id` to retrieve the full, clean Markdown content from our API.\n",
    "4.  **Step 3: Define Analysis:** Define the specific question and the 5-point, enriched JSON schema we want the AI to return.\n",
    "5.  **Step 4: Run Analysis:** Pass the filing's Markdown content and our question to the Gemini model.\n",
    "6.  **Step 5: Review Results:** Display the final, structured analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Load API Keys & Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# FinancialReports API Client\n",
    "from financial_reports_generated_client.client import Client\n",
    "from financial_reports_generated_client.models.filings_list_request import FilingsListRequest\n",
    "from financial_reports_generated_client.models.filings_list_response import FilingsListResponse\n",
    "\n",
    "# Google Gemini API Client\n",
    "import google.generai as genai\n",
    "from google.generai import types\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_api_keys():\n",
    "    \"\"\"Validates that both API keys are loaded into the environment.\"\"\"\n",
    "    fr_api_key = os.environ.get(\"FR_API_KEY\")\n",
    "    gemini_api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "\n",
    "    if not fr_api_key:\n",
    "        print(\"Error: FR_API_KEY not found. Please set it in your .env file.\", file=sys.stderr)\n",
    "        return False\n",
    "    if not gemini_api_key:\n",
    "        print(\"Error: GEMINI_API_KEY not found. Please set it in your .env file.\", file=sys.stderr)\n",
    "        return False\n",
    "    \n",
    "    print(\"Successfully loaded FR_API_KEY and GEMINI_API_KEY.\")\n",
    "    return True\n",
    "\n",
    "if not check_api_keys():\n",
    "    raise ValueError(\"API keys are not configured. Please check your .env file.\")\n",
    "\n",
    "# Initialize the FinancialReports Client\n",
    "fr_client = Client(base_url=\"https://api.financialreports.eu\")\n",
    "fr_client.set_api_key(os.environ.get(\"FR_API_KEY\"))\n",
    "\n",
    "# Initialize the Gemini Client\n",
    "gemini_client = genai.Client(api_key=os.environ.get(\"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Find a Filing\n",
    "\n",
    "Next, we'll use the `financial-reports-generated-client` to find a filing to analyze. \n",
    "\n",
    "For this example, we'll search for a recent **Annual Report** (type `10-K` in our system) from a specific company, **adidas AG** (ISIN `DE000A1EWWW0`). We'll sort by `release_datetime` descending to get the most recent one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Searching for the latest annual report for 'adidas AG'...\")\n",
    "\n",
    "try:\n",
    "    filing_request = FilingsListRequest(\n",
    "        company_isin=\"DE000A1EWWW0\",\n",
    "        type=\"10-K\",            # '10-K' is our code for Annual Reports\n",
    "        ordering=\"-release_datetime\",\n",
    "        page_size=1,              # We only want the single most recent one\n",
    "        view=\"full\"             # Request 'full' view to get the markdown_url\n",
    "    )\n",
    "\n",
    "    # Make the API call\n",
    "    response = fr_client.filings.filings_list(filing_request)\n",
    "\n",
    "    if response and response.results:\n",
    "        filing = response.results[0]\n",
    "        print(f\"Successfully found filing:\")\n",
    "        print(f\"  ID: {filing.id}\")\n",
    "        print(f\"  Title: {filing.title}\")\n",
    "        print(f\"  Markdown URL: {filing.markdown_url}\")\n",
    "    else:\n",
    "        print(\"No matching filing found.\")\n",
    "        filing = None\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while fetching filings: {e}\")\n",
    "    filing = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Fetch Filing Markdown\n",
    "\n",
    "Now we use the `markdown_url` from the filing object. This endpoint provides the full, clean text content of the filing, which is perfect for AI analysis.\n",
    "\n",
    "**Note:** The official `financial-reports-generated-client` does not include the raw markdown endpoint (as it returns plain text, not JSON). We will use the standard `requests` library for this step, authenticated with our API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_markdown(url: str, api_key: str) -> str:\n",
    "    \"\"\"Fetches plain-text content from a URL using API key authentication.\"\"\"\n",
    "    if not url:\n",
    "        print(\"No URL provided.\")\n",
    "        return None\n",
    "    \n",
    "    headers = {\n",
    "        \"X-API-Key\": api_key\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(f\"Fetching markdown from {url}...\")\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(\"Successfully fetched markdown content.\")\n",
    "            return response.text\n",
    "        else:\n",
    "            print(f\"Error fetching markdown. Status: {response.status_code}\")\n",
    "            print(f\"Response: {response.text}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during the request: {e}\")\n",
    "        return None\n",
    "\n",
    "filing_content = None\n",
    "if filing and filing.markdown_url:\n",
    "    filing_content = fetch_markdown(filing.markdown_url, os.environ.get(\"FR_API_KEY\"))\n",
    "\n",
    "if filing_content:\n",
    "    print(f\"\\n--- Start of Markdown (First 1000 chars) ---\\n\")\n",
    "    print(filing_content[:1000])\n",
    "    print(\"\\n--- End of Markdown Preview ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define Analysis\n",
    "\n",
    "This is the most critical step. We define two things:\n",
    "1.  **The Question:** The specific, targeted query we want to ask.\n",
    "2.  **The Schema:** The strict JSON format for the response. This ensures we always get back machine-readable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the Analysis Question\n",
    "# This can be changed to analyze any topic.\n",
    "analysis_question = (\"What is the sentiment regarding the company's 'Business Outlook' and "
     "\"'Forward-Looking Statements' for the next fiscal year? Focus on projections, "
     "\"risks, and overall management tone.\")\n",
    "\n",
    "# 2. Define the Output Schema\n",
    "analysis_schema = types.Schema(\n",
    "    type=types.Type.OBJECT,\n",
    "    required=[\"sentiment_category\", \"rationale\"],\n",
    "    properties={\n",
    "        \"sentiment_category\": types.Schema(\n",
    "            type=types.Type.STRING,\n",
    "            description=\"The single most appropriate sentiment category.\",\n",
    "            enum=[\n",
    "                \"Very Positive\",\n",
    "                \"Positive\",\n",
    "                \"Neutral\",\n",
    "                \"Negative\",\n",
    "                \"Very Negative\",\n",
    "            ],\n",
    "        ),\n",
    "        \"rationale\": types.Schema(\n",
    "            type=types.Type.STRING,\n",
    "            description=\"A brief, 1-2 sentence justification for the chosen \"\n",
    "                        \"sentiment, explaining *why* it was selected.\"\n",
    "        ),\n",
    "        \"supporting_evidence\": types.Schema(\n",
    "            type=types.Type.ARRAY,\n",
    "            description=\"A list of 1-3 direct quotes from the text that \"\n",
    "                        \"support the rationale.\",\n",
    "            items=types.Schema(type=types.Type.STRING)\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"Analysis question defined:\")\n",
    "print(analysis_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run Analysis\n",
    "\n",
    "We pass the full filing content, our question, and our JSON schema to the Gemini API. The `response_mime_type=\"application/json\"` setting is crucial for forcing the model to adhere to our schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(content, question):\n",
    "    \"\"\"Creates the final prompt text to be sent to the model.\"\"\"\n",
    "    return f\"\"\"\n",
    "    You are a professional financial analyst. Your task is to analyze the\n",
    "    following financial document *only* on the text provided.\n",
    "    \n",
    "    You must answer a specific question and provide your response *only*\n",
    "    in the requested JSON format. Do not add any other text before or after\n",
    "    the JSON object.\n",
    "\n",
    "    **Analysis Question:**\n",
    "    {question}\n",
    "\n",
    "    **Full Document Content:**\n",
    "    ---\n",
    "    {content}\n",
    "    ---\n",
    "    \"\"\"\n",
    "\n",
    "def analyze_document_sentiment(client, content, question, schema):\n",
    "    \"\"\"Sends the content and question to the Gemini API for analysis.\"\"\"\n",
    "    if not content:\n",
    "        print(\"Cannot analyze empty content.\")\n",
    "        return None\n",
    "    \n",
    "    model = \"gemini-flash-latest\"\n",
    "    prompt = build_prompt(content, question)\n",
    "\n",
    "    config = types.GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=schema,\n",
    "    )\n",
    "\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[types.Part.from_text(text=prompt)],\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    print(\"Sending content to Gemini for analysis...\")\n",
    "    print(\"(This may take a minute for a large annual report)...\")\n",
    "    try:\n",
    "        # Use the non-streaming generate_content for a single JSON response\n",
    "        response = client.models.generate_content(\n",
    "            model=model,\n",
    "            contents=contents,\n",
    "            config=config,\n",
    "        )\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during API call: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run the analysis\n",
    "analysis_result_text = analyze_document_sentiment(\n",
    "    gemini_client,\n",
    "    filing_content,\n",
    "    analysis_question,\n",
    "    analysis_schema\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Review Results\n",
    "\n",
    "Finally, we parse the JSON text response from the model and print it in a clean, readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analysis_result_text:\n",
    "    print(\"\\n--- Analysis Result ---\")\n",
    "    try:\n",
    "        # Format the JSON for clean printing\n",
    "        parsed_json = json.loads(analysis_result_text)\n",
    "        print(json.dumps(parsed_json, indent=2))\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Failed to decode JSON response from API.\")\n",
    "        print(f\"Raw response: {analysis_result_text}\")\n",
    "    print(\"-----------------------\")\n",
    "else:\n",
    "    print(\"Analysis failed to produce a result.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
