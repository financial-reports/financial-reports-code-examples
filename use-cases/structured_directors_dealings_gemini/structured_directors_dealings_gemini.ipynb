{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Structured Insider Trades (Directors' Dealings) with AI\n",
    "\n",
    "This notebook demonstrates how to convert unstructured insider trade filings (Directors' Dealings, or `DIRS`) into clean, structured JSON using the FinancialReports API and Google's Gemini Flash AI model.\n",
    "\n",
    "### The Value Proposition\n",
    "\n",
    "Clients often need structured data on insider transactions (who bought/sold, what, how much, and at what price). Manually parsing this from raw text filings is difficult and time-consuming, as formats vary.\n",
    "\n",
    "This workflow provides an automated solution. It uses our API to find the filings and a powerful AI model to read the filing's markdown and return a clean, predictable JSON object, saving clients significant development time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "from google.generativeai import types\n",
    "from financialreports_api_client import Client\n",
    "from financialreports_api_client.api.filings import filings_list, filings_markdown_retrieve\n",
    "from financialreports_api_client.models.filings_list_type import FilingsListType\n",
    "from financialreports_api_client.types import Response\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load environment variables from a .env file (if it exists)\n",
    "load_dotenv()\n",
    "\n",
    "# Load API keys from environment\n",
    "FR_API_KEY = os.environ.get(\"FR_API_KEY\")\n",
    "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not FR_API_KEY:\n",
    "    raise ValueError(\"FR_API_KEY not found. Please set it as an environment variable.\")\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found. Please set it as an environment variable.\")\n",
    "\n",
    "logger.info(\"API keys loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configure FinancialReports API Client\n",
    "fr_client = Client(base_url=\"https://api.financialreports.eu\", headers={\"X-API-Key\": FR_API_KEY}, timeout=30.0)\n",
    "\n",
    "# 2. Configure Google Gemini Client\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "logger.info(\"API clients configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- User-Configurable Parameters ---\n",
    "\n",
    "# Define the company you want to search for\n",
    "COMPANY_ISIN = \"DE000A1EWWW0\"  # Example: adidas AG\n",
    "\n",
    "# Define the date range for the search\n",
    "RELEASE_DATE_FROM = \"2024-01-01T00:00:00Z\"\n",
    "\n",
    "# Define the Gemini model to use\n",
    "MODEL_NAME = \"models/gemini-flash-latest\"\n",
    "\n",
    "# --------------------------------------\n",
    "\n",
    "logger.info(f\"Parameters set: ISIN={COMPANY_ISIN}, DateFrom={RELEASE_DATE_FROM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Find DIRS Filings\n",
    "\n",
    "First, we use the `/filings/` endpoint to find all filings with the type `DIRS` for our target company, filtered by our start date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Searching for 'DIRS' filings for ISIN {COMPANY_ISIN}...\")\n",
    "\n",
    "try:\n",
    "    filings_response = filings_list.sync(\n",
    "        client=fr_client,\n",
    "        company_isin=COMPANY_ISIN,\n",
    "        type=FilingsListType.DIRS,\n",
    "        release_datetime_from=RELEASE_DATE_FROM,\n",
    "        page_size=10  # Limiting to 10 for this example\n",
    "    )\n",
    "\n",
    "    if filings_response and filings_response.results:\n",
    "        filings_to_process = filings_response.results\n",
    "        logger.info(f\"Found {filings_response.count} total filings. Processing first {len(filings_to_process)}.\")\n",
    "        \n",
    "        # Display the first filing found as a confirmation\n",
    "        print(f\"--- Example Filing Found ---\")\n",
    "        print(f\"ID: {filings_to_process[0].id}\")\n",
    "        print(f\"Title: {filings_to_process[0].title}\")\n",
    "        print(f\"Release Date: {filings_to_process[0].release_datetime}\")\n",
    "        print(f\"Company: {filings_to_process[0].company.name}\")\n",
    "        print(\"----------------------------\")\n",
    "    else:\n",
    "        filings_to_process = []\n",
    "        logger.warning(\"No 'DIRS' filings found matching the criteria.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error fetching filings: {e}\")\n",
    "    filings_to_process = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the Structured Output Schema\n",
    "\n",
    "This is the most critical step. We define a `Schema` object that tells the Gemini model *exactly* what data to extract and what the final JSON structure must look like.\n",
    "\n",
    "This schema enforces the data types (string, number, list) and structure (nested objects), ensuring the AI's output is reliable and predictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_schema = types.Schema(\n",
    "    type=types.Type.OBJECT,\n",
    "    properties={\n",
    "        \"transaction_date\": types.Schema(type=types.Type.STRING, description=\"The date of the transaction (YYYY-MM-DD)\"),\n",
    "        \"financial_instrument\": types.Schema(type=types.Type.STRING, description=\"The financial instrument, e.g., 'Shares' or 'Stock Options'\"),\n",
    "        \"nature_of_transaction\": types.Schema(type=types.Type.STRING, description=\"The nature of the transaction, e.g., 'Acquisition', 'Disposal' or 'Purchase'\"),\n",
    "        \"price\": types.Schema(type=types.Type.NUMBER, description=\"The price per unit of the instrument\"),\n",
    "        \"currency\": types.Schema(type=types.Type.STRING, description=\"The currency of the transaction (e.g., 'EUR', 'GBP')\"),\n",
    "        \"volume\": types.Schema(type=types.Type.NUMBER, description=\"The number of units transacted\"),\n",
    "        \"total_value\": types.Schema(type=types.Type.NUMBER, description=\"The total value of the transaction (Price * Volume)\"),\n",
    "        \"venue\": types.Schema(type=types.Type.STRING, description=\"The trading venue, e.g., 'XETRA', 'Outside a trading venue'\")\n",
    "    }\n",
    ")\n",
    "\n",
    "reporting_person_schema = types.Schema(\n",
    "    type=types.Type.OBJECT,\n",
    "    properties={\n",
    "        \"name\": types.Schema(type=types.Type.STRING, description=\"The name of the reporting person (e.g., 'John Doe')\"),\n",
    "        \"position\": types.Schema(type=types.Type.STRING, description=\"The position of the person, e.g., 'CEO', 'Member of the Supervisory Board'\")\n",
    "    }\n",
    ")\n",
    "\n",
    "dirs_schema = types.Schema(\n",
    "    type=types.Type.OBJECT,\n",
    "    properties={\n",
    "        \"issuer_name\": types.Schema(type=types.Type.STRING, description=\"The name of the company issuing the securities\"),\n",
    "        \"issuer_isin\": types.Schema(type=types.Type.STRING, description=\"The ISIN of the issuing company\"),\n",
    "        \"reporting_person_details\": reporting_person_schema,\n",
    "        \"transactions\": types.Schema(\n",
    "            type=types.Type.ARRAY,\n",
    "            description=\"A list of all transactions reported in this filing\",\n",
    "            items=transaction_schema\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "logger.info(\"Structured output schema defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create AI Extraction Function\n",
    "\n",
    "Now we create a helper function that does all the work:\n",
    "1.  Takes a `filing_id` as input.\n",
    "2.  Fetches the filing's markdown content from our API.\n",
    "3.  Creates a prompt that includes the markdown.\n",
    "4.  Configures the Gemini model to use our schema and output JSON.\n",
    "5.  Calls the model and returns the parsed JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_structured_data(filing_id: int) -> dict | None:\n",
    "    \"\"\"\n",
    "    Fetches markdown for a filing and uses Gemini to extract structured data.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Processing filing_id: {filing_id}...\")\n",
    "    \n",
    "    # 1. Fetch markdown content from FinancialReports API\n",
    "    try:\n",
    "        markdown_response: Response[str] = filings_markdown_retrieve.sync(\n",
    "            client=fr_client,\n",
    "            filing_id=filing_id\n",
    "        )\n",
    "        markdown_content = markdown_response.parsed\n",
    "        if not markdown_content:\n",
    "            logger.warning(f\"No markdown content found for filing_id: {filing_id}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching markdown for filing_id {filing_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 2. Build the prompt for the Gemini model\n",
    "    prompt = f\"\"\"\n",
    "    Extract the directors' dealing (insider trade) information from the following financial filing.\n",
    "    Provide all monetary values as numbers, not strings.\n",
    "    Ensure the 'transaction_date' is in 'YYYY-MM-DD' format.\n",
    "    If multiple transactions are listed, include all of them in the 'transactions' list.\n",
    "\n",
    "    Filing Content:\n",
    "    ---\n",
    "    {markdown_content}\n",
    "    ---\n",
    "    \"\"\"\n",
    "    \n",
    "    contents = [types.Part.from_text(prompt)]\n",
    "\n",
    "    # 3. Configure and call the Gemini model\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=MODEL_NAME,\n",
    "        generation_config=types.GenerationConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=dirs_schema,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(contents)\n",
    "        \n",
    "        # 4. Parse and return the JSON data\n",
    "        # The model.generate_content call now directly returns a response\n",
    "        # The 'text' attribute contains the JSON string when in JSON mode.\n",
    "        json_data = json.loads(response.text)\n",
    "        logger.info(f\"Successfully extracted data for filing_id: {filing_id}\")\n",
    "        return json_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating content for filing_id {filing_id}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Execute Workflow & Aggregate Results\n",
    "\n",
    "Now we loop through the list of `filings_to_process` we found in Step 1.\n",
    "\n",
    "We'll call our `extract_structured_data` function for each one and store the results in a list. We also add our own `filing_id` to the result for easy cross-referencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_structured_data = []\n",
    "processed_count = 0\n",
    "\n",
    "if not filings_to_process:\n",
    "    logger.warning(\"No filings to process. Skipping extraction loop.\")\n",
    "else:\n",
    "    for filing in filings_to_process:\n",
    "        if filing.id is None:\n",
    "            continue\n",
    "            \n",
    "        data = extract_structured_data(filing.id)\n",
    "        \n",
    "        if data:\n",
    "            # Add our own metadata for context\n",
    "            data['filing_id'] = filing.id\n",
    "            data['filing_title'] = filing.title\n",
    "            data['filing_release_datetime'] = str(filing.release_datetime)\n",
    "            all_structured_data.append(data)\n",
    "            processed_count += 1\n",
    "\n",
    "logger.info(f\"--- Workflow Complete ---\")\n",
    "logger.info(f\"Successfully processed {processed_count} out of {len(filings_to_process)} filings.\")\n",
    "\n",
    "# Display the raw nested JSON output for the first result\n",
    "if all_structured_data:\n",
    "    print(\"\\n--- Raw JSON Output (First Result) ---\")\n",
    "    print(json.dumps(all_structured_data[0], indent=2))\n",
    "else:\n",
    "    print(\"\\nNo structured data was extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Analyze and Flatten Data with Pandas\n",
    "\n",
    "The raw JSON output is useful, but it's nested. For many analyses (e.g., in Excel or a BI tool), a flat table is better.\n",
    "\n",
    "We can use `pandas.json_normalize` to instantly 'flatten' our data. We tell it to use the `transactions` list as the main records (`record_path`) and to pull in the top-level details (like `filing_id` and `issuer_name`) as columns for each record (`meta`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all_structured_data:\n",
    "    logger.warning(\"No data to flatten. Skipping pandas DataFrame creation.\")\n",
    "else:\n",
    "    try:\n",
    "        # Define which top-level keys to merge into each transaction row\n",
    "        meta_keys = [\n",
    "            'filing_id',\n",
    "            'filing_title',\n",
    "            'filing_release_datetime',\n",
    "            'issuer_name',\n",
    "            'issuer_isin',\n",
    "            ['reporting_person_details', 'name'],\n",
    "            ['reporting_person_details', 'position']\n",
    "        ]\n",
    "\n",
    "        # Use json_normalize to flatten the data\n",
    "        df_transactions = pd.json_normalize(\n",
    "            all_structured_data, \n",
    "            record_path=['transactions'], \n",
    "            meta=meta_keys,\n",
    "            errors='ignore'  # Skip if a record has no 'transactions'\n",
    "        )\n",
    "\n",
    "        # Rename flattened columns for clarity\n",
    "        df_transactions.rename(columns={\n",
    "            'reporting_person_details.name': 'person_name',\n",
    "            'reporting_person_details.position': 'person_position'\n",
    "        }, inplace=True)\n",
    "\n",
    "        print(\"\\n--- Flattened DataFrame of All Transactions ---\")\n",
    "        display(df_transactions)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error flattening data with pandas: {e}\")\n",
    "        print(\"Could not create DataFrame. Displaying raw data instead:\")\n",
    "        print(all_structured_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In just a few steps, we have built a powerful pipeline that:\n",
    "1.  Identified relevant filings using the FinancialReports API.\n",
    "2.  Fetched the raw text content for each one.\n",
    "3.  Used Google's Gemini Flash model to parse the text into a guaranteed-valid JSON structure.\n",
    "4.  Aggregated and flattened this data into a single, analysis-ready DataFrame.\n",
    "\n",
    "This `DataFrame` can now be easily exported to a CSV, loaded into a database, or used for further financial analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
